{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1765643,"sourceType":"datasetVersion","datasetId":1049526}],"dockerImageVersionId":30077,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport string, os \nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:35.906214Z","iopub.execute_input":"2022-04-19T05:43:35.906714Z","iopub.status.idle":"2022-04-19T05:43:39.974798Z","shell.execute_reply.started":"2022-04-19T05:43:35.906604Z","shell.execute_reply":"2022-04-19T05:43:39.973941Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:39.976678Z","iopub.execute_input":"2022-04-19T05:43:39.977024Z","iopub.status.idle":"2022-04-19T05:43:39.987417Z","shell.execute_reply.started":"2022-04-19T05:43:39.976968Z","shell.execute_reply":"2022-04-19T05:43:39.986143Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 200  # Number of epochs to train for.\nlatent_dim = 512  # Latent dimensionality of the encoding space.\nnum_samples = 50000","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:39.991621Z","iopub.execute_input":"2022-04-19T05:43:39.992033Z","iopub.status.idle":"2022-04-19T05:43:39.996434Z","shell.execute_reply.started":"2022-04-19T05:43:39.991959Z","shell.execute_reply":"2022-04-19T05:43:39.995444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reading dataset\ndf = pd.read_csv('../input/chatbot-dataset-topical-chat/topical_chat.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:39.999897Z","iopub.execute_input":"2022-04-19T05:43:40.000561Z","iopub.status.idle":"2022-04-19T05:43:40.455188Z","shell.execute_reply.started":"2022-04-19T05:43:40.000522Z","shell.execute_reply":"2022-04-19T05:43:40.454311Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# basic preprocessing\ndef process(text):\n    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n          .replace('\"', ' ').replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n\n    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n\n    text = \" \".join(text.split())\n    #text+=\"<eos>\"\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:40.45858Z","iopub.execute_input":"2022-04-19T05:43:40.458939Z","iopub.status.idle":"2022-04-19T05:43:40.465031Z","shell.execute_reply.started":"2022-04-19T05:43:40.458903Z","shell.execute_reply":"2022-04-19T05:43:40.464111Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.message = df.message.apply(process)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:40.466577Z","iopub.execute_input":"2022-04-19T05:43:40.467201Z","iopub.status.idle":"2022-04-19T05:43:44.160277Z","shell.execute_reply.started":"2022-04-19T05:43:40.467166Z","shell.execute_reply":"2022-04-19T05:43:44.159461Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:44.161536Z","iopub.execute_input":"2022-04-19T05:43:44.161876Z","iopub.status.idle":"2022-04-19T05:43:44.171631Z","shell.execute_reply.started":"2022-04-19T05:43:44.161841Z","shell.execute_reply":"2022-04-19T05:43:44.170659Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_words_set = set()\ntarget_words_set = set()\n\nfor conversation_index in tqdm(range(df.shape[0])):\n    \n    if conversation_index == 0:\n        continue\n        \n    input_text = df.iloc[conversation_index - 1]\n    target_text = df.iloc[conversation_index]\n    \n    if input_text.conversation_id == target_text.conversation_id:\n        \n        input_text = input_text.message\n        target_text = target_text.message\n        \n        if len(input_text.split()) > 2 and \\\n            len(target_text.split()) > 0 and \\\n            len(input_text.split()) < 30 and \\\n            len(target_text.split()) < 10 and \\\n            input_text and \\\n            target_text:\n            \n            target_text = \"bos \" + target_text + \" eos\"\n                \n            input_texts.append(input_text)\n            target_texts.append(target_text)\n            \n            for word in input_text.split():\n                if word not in input_words_set:\n                    input_words_set.add(word)\n            for word in target_text.split():\n                if word not in target_words_set:\n                    target_words_set.add(word)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:43:44.173175Z","iopub.execute_input":"2022-04-19T05:43:44.173748Z","iopub.status.idle":"2022-04-19T05:44:37.166397Z","shell.execute_reply.started":"2022-04-19T05:43:44.173702Z","shell.execute_reply":"2022-04-19T05:44:37.165437Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_texts","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:44:37.16762Z","iopub.execute_input":"2022-04-19T05:44:37.16796Z","iopub.status.idle":"2022-04-19T05:44:37.195852Z","shell.execute_reply.started":"2022-04-19T05:44:37.167923Z","shell.execute_reply":"2022-04-19T05:44:37.194965Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_texts","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:44:37.196904Z","iopub.execute_input":"2022-04-19T05:44:37.197249Z","iopub.status.idle":"2022-04-19T05:44:37.223437Z","shell.execute_reply.started":"2022-04-19T05:44:37.197206Z","shell.execute_reply":"2022-04-19T05:44:37.222782Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow_datasets as tfds\n\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport math\n\nimport matplotlib.pyplot as plt\nMAX_SENTENCE_LENGTH = 60","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:44:37.225727Z","iopub.execute_input":"2022-04-19T05:44:37.226027Z","iopub.status.idle":"2022-04-19T05:44:37.622498Z","shell.execute_reply.started":"2022-04-19T05:44:37.225994Z","shell.execute_reply":"2022-04-19T05:44:37.621733Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n    input_texts + target_texts, target_vocab_size=2**13)\n\nSTART_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n\nVOCAB_SIZE = tokenizer.vocab_size + 2","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:44:37.623634Z","iopub.execute_input":"2022-04-19T05:44:37.623964Z","iopub.status.idle":"2022-04-19T05:45:02.677168Z","shell.execute_reply.started":"2022-04-19T05:44:37.623931Z","shell.execute_reply":"2022-04-19T05:45:02.676308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_and_filter(input_texts, target_texts):\n  tokenized_inputs, tokenized_outputs = [], []\n  \n  for (sentence1, sentence2) in zip(input_texts, target_texts):\n    # tokenize sentence\n    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n    # check tokenized sentence max length\n    if len(sentence1) <= MAX_SENTENCE_LENGTH and len(sentence2) <= MAX_SENTENCE_LENGTH:\n      tokenized_inputs.append(sentence1)\n      tokenized_outputs.append(sentence2)\n  \n  # pad tokenized sentences\n  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n      tokenized_inputs, maxlen=MAX_SENTENCE_LENGTH, padding='post')\n  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n      tokenized_outputs, maxlen=MAX_SENTENCE_LENGTH, padding='post')\n  \n  return tokenized_inputs, tokenized_outputs\n\n\ninput_texts, target_texts = tokenize_and_filter(input_texts, target_texts)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:02.678502Z","iopub.execute_input":"2022-04-19T05:45:02.678819Z","iopub.status.idle":"2022-04-19T05:45:04.528703Z","shell.execute_reply.started":"2022-04-19T05:45:02.678784Z","shell.execute_reply":"2022-04-19T05:45:04.527791Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Vocab size: {}'.format(VOCAB_SIZE))\nprint('Number of samples: {}'.format(len(input_texts)))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:04.529946Z","iopub.execute_input":"2022-04-19T05:45:04.530303Z","iopub.status.idle":"2022-04-19T05:45:04.536778Z","shell.execute_reply.started":"2022-04-19T05:45:04.530268Z","shell.execute_reply":"2022-04-19T05:45:04.535889Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 64\nBUFFER_SIZE = 20000\n\ndataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'inputs': input_texts,\n        'dec_inputs': target_texts[:, :-1]\n    },\n    {\n        'outputs': target_texts[:, 1:]\n    },\n))\n\ndataset = dataset.cache()\ndataset = dataset.shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE)\ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:04.538086Z","iopub.execute_input":"2022-04-19T05:45:04.538632Z","iopub.status.idle":"2022-04-19T05:45:06.301665Z","shell.execute_reply.started":"2022-04-19T05:45:04.538595Z","shell.execute_reply":"2022-04-19T05:45:06.300854Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Attention","metadata":{}},{"cell_type":"code","source":"def scaled_dot_product_attention(query, key, value, mask):\n  \"\"\"Calculate the attention weights. \"\"\"\n  matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n  # scale matmul_qk\n  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n  logits = matmul_qk / tf.math.sqrt(depth)\n\n  # add the mask to zero out padding tokens\n  if mask is not None:\n    logits += (mask * -1e9)\n\n  # softmax is normalized on the last axis (seq_len_k)\n  attention_weights = tf.nn.softmax(logits, axis=-1)\n\n  output = tf.matmul(attention_weights, value)\n\n  return output","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.302921Z","iopub.execute_input":"2022-04-19T05:45:06.30327Z","iopub.status.idle":"2022-04-19T05:45:06.312268Z","shell.execute_reply.started":"2022-04-19T05:45:06.303236Z","shell.execute_reply":"2022-04-19T05:45:06.311489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n        'value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # linear layers\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # split heads\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    # scaled dot-product attention\n    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    # concatenation of heads\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    # final linear layer\n    outputs = self.dense(concat_attention)\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.313913Z","iopub.execute_input":"2022-04-19T05:45:06.314423Z","iopub.status.idle":"2022-04-19T05:45:06.327162Z","shell.execute_reply.started":"2022-04-19T05:45:06.314384Z","shell.execute_reply":"2022-04-19T05:45:06.326425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformer","metadata":{}},{"cell_type":"markdown","source":"**Masking**","metadata":{}},{"cell_type":"code","source":"def create_padding_mask(x):\n  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n  # (batch_size, 1, 1, sequence length)\n  return mask[:, tf.newaxis, tf.newaxis, :]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.328561Z","iopub.execute_input":"2022-04-19T05:45:06.329057Z","iopub.status.idle":"2022-04-19T05:45:06.33893Z","shell.execute_reply.started":"2022-04-19T05:45:06.329004Z","shell.execute_reply":"2022-04-19T05:45:06.337883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.340159Z","iopub.execute_input":"2022-04-19T05:45:06.34056Z","iopub.status.idle":"2022-04-19T05:45:06.640604Z","shell.execute_reply.started":"2022-04-19T05:45:06.340462Z","shell.execute_reply":"2022-04-19T05:45:06.638852Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_look_ahead_mask(x):\n  seq_len = tf.shape(x)[1]\n  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n  padding_mask = create_padding_mask(x)\n  return tf.maximum(look_ahead_mask, padding_mask)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.642019Z","iopub.execute_input":"2022-04-19T05:45:06.642399Z","iopub.status.idle":"2022-04-19T05:45:06.650161Z","shell.execute_reply.started":"2022-04-19T05:45:06.642367Z","shell.execute_reply":"2022-04-19T05:45:06.648929Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.652438Z","iopub.execute_input":"2022-04-19T05:45:06.653411Z","iopub.status.idle":"2022-04-19T05:45:06.681048Z","shell.execute_reply.started":"2022-04-19T05:45:06.653366Z","shell.execute_reply":"2022-04-19T05:45:06.680031Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Positional Encoding","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(tf.keras.layers.Layer):\n\n  def __init__(self, position, d_model):\n    super(PositionalEncoding, self).__init__()\n    self.pos_encoding = self.positional_encoding(position, d_model)\n\n  def get_angles(self, position, i, d_model):\n    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n    return position * angles\n\n  def positional_encoding(self, position, d_model):\n    angle_rads = self.get_angles(\n        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n        d_model=d_model)\n    # apply sin to even index in the array\n    sines = tf.math.sin(angle_rads[:, 0::2])\n    # apply cos to odd index in the array\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    pos_encoding = tf.concat([sines, cosines], axis=-1)\n    pos_encoding = pos_encoding[tf.newaxis, ...]\n    return tf.cast(pos_encoding, tf.float32)\n\n  def call(self, inputs):\n    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.683723Z","iopub.execute_input":"2022-04-19T05:45:06.684267Z","iopub.status.idle":"2022-04-19T05:45:06.694801Z","shell.execute_reply.started":"2022-04-19T05:45:06.684228Z","shell.execute_reply":"2022-04-19T05:45:06.693645Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_pos_encoding = PositionalEncoding(50, 512)\n\nplt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\nplt.xlabel('Depth')\nplt.xlim((0, 512))\nplt.ylabel('Position')\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.696306Z","iopub.execute_input":"2022-04-19T05:45:06.696804Z","iopub.status.idle":"2022-04-19T05:45:06.9578Z","shell.execute_reply.started":"2022-04-19T05:45:06.696762Z","shell.execute_reply":"2022-04-19T05:45:06.956972Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoder Layer","metadata":{}},{"cell_type":"markdown","source":"**1) Multi head attention\n2) Two dense layers followed by dropout**","metadata":{}},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': padding_mask\n      })\n  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n  attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.959109Z","iopub.execute_input":"2022-04-19T05:45:06.959448Z","iopub.status.idle":"2022-04-19T05:45:06.967584Z","shell.execute_reply.started":"2022-04-19T05:45:06.959411Z","shell.execute_reply":"2022-04-19T05:45:06.96664Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_encoder_layer = encoder_layer(\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_encoder_layer\")\n\ntf.keras.utils.plot_model(\n    sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:06.969239Z","iopub.execute_input":"2022-04-19T05:45:06.969667Z","iopub.status.idle":"2022-04-19T05:45:07.845662Z","shell.execute_reply.started":"2022-04-19T05:45:06.969633Z","shell.execute_reply":"2022-04-19T05:45:07.844746Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Encoder : It consists of \n# \n# a) Input emdedding\n# b) Positional Encoding\n# c) num_layers encoder layers","metadata":{}},{"cell_type":"code","source":"def encoder(vocab_size,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            name=\"encoder\"):\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n  for i in range(num_layers):\n    outputs = encoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name=\"encoder_layer_{}\".format(i),\n    )([outputs, padding_mask])\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:07.847335Z","iopub.execute_input":"2022-04-19T05:45:07.847859Z","iopub.status.idle":"2022-04-19T05:45:07.857373Z","shell.execute_reply.started":"2022-04-19T05:45:07.847817Z","shell.execute_reply":"2022-04-19T05:45:07.856566Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_encoder = encoder(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_encoder\")\n\ntf.keras.utils.plot_model(\n   sample_encoder, to_file='encoder.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:07.859464Z","iopub.execute_input":"2022-04-19T05:45:07.859772Z","iopub.status.idle":"2022-04-19T05:45:08.60588Z","shell.execute_reply.started":"2022-04-19T05:45:07.859745Z","shell.execute_reply":"2022-04-19T05:45:08.604926Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Decoder Layer\n\nEach consists of:\na) Masked multi self head attention\nb) Multi head attention(with padding mask) . value and key receive the encoder output as inputs. query receives the output from the masked multi-head attention sublayer.\nc) 2 dense layers followed by dropout**","metadata":{}},{"cell_type":"code","source":"def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name=\"look_ahead_mask\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n\n  attention1 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_1\")(inputs={\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': look_ahead_mask\n      })\n  attention1 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention1 + inputs)\n\n  attention2 = MultiHeadAttention(\n      d_model, num_heads, name=\"attention_2\")(inputs={\n          'query': attention1,\n          'key': enc_outputs,\n          'value': enc_outputs,\n          'mask': padding_mask\n      })\n  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n  attention2 = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention2 + attention1)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(outputs + attention2)\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:08.60762Z","iopub.execute_input":"2022-04-19T05:45:08.608223Z","iopub.status.idle":"2022-04-19T05:45:08.619464Z","shell.execute_reply.started":"2022-04-19T05:45:08.608175Z","shell.execute_reply":"2022-04-19T05:45:08.618463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_decoder_layer = decoder_layer(\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_decoder_layer\")\n\ntf.keras.utils.plot_model(\n    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:08.620783Z","iopub.execute_input":"2022-04-19T05:45:08.621364Z","iopub.status.idle":"2022-04-19T05:45:09.130601Z","shell.execute_reply.started":"2022-04-19T05:45:08.621326Z","shell.execute_reply":"2022-04-19T05:45:09.129633Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Decoder\nThe Decoder consists of:\n\n1) Output Embedding\n2) Positional Encoding\n3) N decoder layers**","metadata":{}},{"cell_type":"code","source":"def decoder(vocab_size,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            name='decoder'):\n  inputs = tf.keras.Input(shape=(None,), name='inputs')\n  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n  look_ahead_mask = tf.keras.Input(\n      shape=(1, None, None), name='look_ahead_mask')\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n  \n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n\n  for i in range(num_layers):\n    outputs = decoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name='decoder_layer_{}'.format(i),\n    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n\n  return tf.keras.Model(\n      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n      outputs=outputs,\n      name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:09.1321Z","iopub.execute_input":"2022-04-19T05:45:09.132598Z","iopub.status.idle":"2022-04-19T05:45:09.143531Z","shell.execute_reply.started":"2022-04-19T05:45:09.132557Z","shell.execute_reply":"2022-04-19T05:45:09.142569Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_decoder = decoder(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_decoder\")\n\ntf.keras.utils.plot_model(\n    sample_decoder, to_file='decoder.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:09.149418Z","iopub.execute_input":"2022-04-19T05:45:09.149683Z","iopub.status.idle":"2022-04-19T05:45:10.373217Z","shell.execute_reply.started":"2022-04-19T05:45:09.149659Z","shell.execute_reply":"2022-04-19T05:45:10.372121Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformer\n**Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned.**","metadata":{}},{"cell_type":"code","source":"def transformer(vocab_size,\n                num_layers,\n                units,\n                d_model,\n                num_heads,\n                dropout,\n                name=\"transformer\"):\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n\n  enc_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='enc_padding_mask')(inputs)\n  # mask the future tokens for decoder inputs at the 1st attention block\n  look_ahead_mask = tf.keras.layers.Lambda(\n      create_look_ahead_mask,\n      output_shape=(1, None, None),\n      name='look_ahead_mask')(dec_inputs)\n  # mask the encoder outputs for the 2nd attention block\n  dec_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='dec_padding_mask')(inputs)\n\n  enc_outputs = encoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[inputs, enc_padding_mask])\n\n  dec_outputs = decoder(\n      vocab_size=vocab_size,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n\n  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n\n  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:10.375109Z","iopub.execute_input":"2022-04-19T05:45:10.375813Z","iopub.status.idle":"2022-04-19T05:45:10.386078Z","shell.execute_reply.started":"2022-04-19T05:45:10.375767Z","shell.execute_reply":"2022-04-19T05:45:10.385389Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_transformer = transformer(\n    vocab_size=8515,\n    num_layers=2,\n    units=512,\n    d_model=256,\n    num_heads=8,\n    dropout=0.1,\n    name=\"our_transformer\")\n\ntf.keras.utils.plot_model(\n    sample_transformer, to_file='transformer.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:10.389002Z","iopub.execute_input":"2022-04-19T05:45:10.389397Z","iopub.status.idle":"2022-04-19T05:45:12.758596Z","shell.execute_reply.started":"2022-04-19T05:45:10.389359Z","shell.execute_reply":"2022-04-19T05:45:12.757577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Train the model**","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\n# Hyper-parameters\nNUM_LAYERS = 2\nD_MODEL = 256\nNUM_HEADS = 8\nUNITS = 512\nDROPOUT = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:12.760149Z","iopub.execute_input":"2022-04-19T05:45:12.760665Z","iopub.status.idle":"2022-04-19T05:45:12.769288Z","shell.execute_reply.started":"2022-04-19T05:45:12.760624Z","shell.execute_reply":"2022-04-19T05:45:12.768447Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = transformer(\n    vocab_size=VOCAB_SIZE,\n    num_layers=NUM_LAYERS,\n    units=UNITS,\n    d_model=D_MODEL,\n    num_heads=NUM_HEADS,\n    dropout=DROPOUT)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:12.770619Z","iopub.execute_input":"2022-04-19T05:45:12.771018Z","iopub.status.idle":"2022-04-19T05:45:14.778001Z","shell.execute_reply.started":"2022-04-19T05:45:12.770961Z","shell.execute_reply":"2022-04-19T05:45:14.777194Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loss function","metadata":{}},{"cell_type":"code","source":"def loss_function(y_true, y_pred):\n  y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n  \n  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n      from_logits=True, reduction='none')(y_true, y_pred)\n\n  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n  loss = tf.multiply(loss, mask)\n\n  return tf.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.779814Z","iopub.execute_input":"2022-04-19T05:45:14.780316Z","iopub.status.idle":"2022-04-19T05:45:14.786723Z","shell.execute_reply.started":"2022-04-19T05:45:14.780277Z","shell.execute_reply":"2022-04-19T05:45:14.785874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n\n  def __init__(self, d_model, warmup_steps=2000):\n    super(CustomSchedule, self).__init__()\n\n    self.d_model = d_model\n    self.d_model = tf.cast(self.d_model, tf.float32)\n\n    self.warmup_steps = warmup_steps\n\n  def __call__(self, step):\n    arg1 = tf.math.rsqrt(step)\n    arg2 = step * (self.warmup_steps**-1.5)\n\n    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.787948Z","iopub.execute_input":"2022-04-19T05:45:14.788316Z","iopub.status.idle":"2022-04-19T05:45:14.796996Z","shell.execute_reply.started":"2022-04-19T05:45:14.788281Z","shell.execute_reply":"2022-04-19T05:45:14.79608Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_learning_rate = CustomSchedule(d_model=256)\n\nplt.plot(sample_learning_rate(tf.range(3768, dtype=tf.float32)))\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"Train Step\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.798502Z","iopub.execute_input":"2022-04-19T05:45:14.798847Z","iopub.status.idle":"2022-04-19T05:45:14.966845Z","shell.execute_reply.started":"2022-04-19T05:45:14.798812Z","shell.execute_reply":"2022-04-19T05:45:14.966145Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Compile the model**","metadata":{}},{"cell_type":"code","source":"def perplexity(real, pred):\n    \"\"\"\n    This function returns the perplexity for model's predictions on a batch \n    of data in comparison with the real outputs at a timestep.\n    Arguments:\n        real: real output, a Tensorflow tensor with a shape \n              of: (batch_size, max_seq_length)\n        pred: model's predictions at a certain timestep, a Tensorflow tensor \n              with a shape of: (batch_size, max_seq_length)\n    Returns:\n        A Tensorflow tensor with the perplexity.\n    \"\"\"\n    real = tf.reshape(real, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n    loss = loss_function(real, pred)\n    \n    return tf.cast(tf.pow(math.e, loss), dtype=tf.keras.backend.floatx())","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.968816Z","iopub.execute_input":"2022-04-19T05:45:14.969168Z","iopub.status.idle":"2022-04-19T05:45:14.976376Z","shell.execute_reply.started":"2022-04-19T05:45:14.969131Z","shell.execute_reply":"2022-04-19T05:45:14.975649Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def accuracy(y_true, y_pred):\n  # ensure labels have shape (batch_size, MAX_SENTENCE_LENGTH - 1)\n  y_true = tf.reshape(y_true, shape=(-1, MAX_SENTENCE_LENGTH - 1))\n  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.97853Z","iopub.execute_input":"2022-04-19T05:45:14.978948Z","iopub.status.idle":"2022-04-19T05:45:14.983529Z","shell.execute_reply.started":"2022-04-19T05:45:14.978909Z","shell.execute_reply":"2022-04-19T05:45:14.98259Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learning_rate = CustomSchedule(D_MODEL)\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n\n\nmodel.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy, perplexity], run_eagerly=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:14.985095Z","iopub.execute_input":"2022-04-19T05:45:14.98574Z","iopub.status.idle":"2022-04-19T05:45:15.00652Z","shell.execute_reply.started":"2022-04-19T05:45:14.985674Z","shell.execute_reply":"2022-04-19T05:45:15.005698Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 100\n\nhistory = model.fit(dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T05:45:15.007764Z","iopub.execute_input":"2022-04-19T05:45:15.00812Z","iopub.status.idle":"2022-04-19T07:38:23.686672Z","shell.execute_reply.started":"2022-04-19T05:45:15.008087Z","shell.execute_reply":"2022-04-19T07:38:23.685913Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history","metadata":{"execution":{"iopub.status.busy":"2022-04-19T07:49:15.347804Z","iopub.execute_input":"2022-04-19T07:49:15.348169Z","iopub.status.idle":"2022-04-19T07:49:15.356423Z","shell.execute_reply.started":"2022-04-19T07:49:15.348137Z","shell.execute_reply":"2022-04-19T07:49:15.354257Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'],label='Training_loss')\nplt.legend()\nplt.title('Training loss')\nplt.xlabel('Np.of epochs')\nplt.ylabel('Loss')\nplt.show()\nplt.savefig('Loss_Graph')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T08:17:35.533755Z","iopub.execute_input":"2022-04-19T08:17:35.534105Z","iopub.status.idle":"2022-04-19T08:17:35.685758Z","shell.execute_reply.started":"2022-04-19T08:17:35.53407Z","shell.execute_reply":"2022-04-19T08:17:35.685061Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'],label='Training_accuracy')\nplt.legend()\nplt.title('Accuracy')\nplt.xlabel('No.of epochs')\nplt.ylabel('Accuracy')\nplt.show()\nplt.savefig('Loss_Graph')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T08:18:38.49283Z","iopub.execute_input":"2022-04-19T08:18:38.493177Z","iopub.status.idle":"2022-04-19T08:18:38.646578Z","shell.execute_reply.started":"2022-04-19T08:18:38.493145Z","shell.execute_reply":"2022-04-19T08:18:38.645923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['perplexity'],label='perplexity')\nplt.legend()\nplt.title('Perplexity')\nplt.xlabel('No.of epochs')\nplt.ylabel('perplexity')\nplt.show()\nplt.savefig('Loss_Graph')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T08:34:12.938907Z","iopub.execute_input":"2022-04-19T08:34:12.939251Z","iopub.status.idle":"2022-04-19T08:34:13.124859Z","shell.execute_reply.started":"2022-04-19T08:34:12.939214Z","shell.execute_reply":"2022-04-19T08:34:13.12421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}